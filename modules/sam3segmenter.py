"""
Created by Yinghao Ho on 2026-1-26
"""

from typing import List, Dict, Optional, Union, Tuple
from pathlib import Path

import numpy as np
import cv2
import torch
from PIL import Image

from sam3.model_builder import build_sam3_image_model
from sam3.model.sam3_image_processor import Sam3Processor
from configs.part_config import PartConfig


class SAM3Segmenter:
    """
    SAM3éƒ¨ä»¶åˆ†å‰²å™¨
    
    ä½¿ç”¨SAM3æ¨¡å‹åˆ†å‰²ç‰©ä½“çš„å„ä¸ªéƒ¨ä»¶ï¼Œå¹¶ä¸ºæ¯ä¸ªéƒ¨ä»¶æå–ä¸€ä¸ªå…³é”®ç‚¹ã€‚
    å…³é”®ç‚¹æå–ä½¿ç”¨è´¨å¿ƒ+æœ€è¿‘ç‚¹æŠ•å½±æ–¹æ³•ï¼Œç¡®ä¿å…³é”®ç‚¹è½åœ¨maskè¡¨é¢ä¸Šã€‚
    
    å·¥ä½œæµç¨‹ï¼š
        1. æ ¹æ®ç‰©ä½“labelä»PartConfigè·å–éƒ¨ä»¶åˆ—è¡¨
        2. ä½¿ç”¨SAM3é€ä¸ªåˆ†å‰²éƒ¨ä»¶ï¼ˆfeature reuseä¼˜åŒ–ï¼‰
        3. ä¸ºæ¯ä¸ªéƒ¨ä»¶æå–å•ä¸ªå…³é”®ç‚¹
        4. å°†å…³é”®ç‚¹åæ ‡è½¬æ¢åˆ°åŸå§‹å›¾åƒåæ ‡ç³»
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        >>> segmenter = SAM3Segmenter()
        >>> results = segmenter.segment_parts(
        ...     cropped_image=cup_image,
        ...     label="cup",
        ...     crop_bbox=[128, 144, 512, 432]
        ... )
        >>> for result in results:
        ...     print(f"{result['part_name']}: {result['keypoint']}")
    """
    
    def __init__(self, 
                 checkpoint_path: Optional[str] = None,
                 device: str = "cuda"):
        """
        åˆå§‹åŒ–SAM3åˆ†å‰²å™¨
        
        Args:
            checkpoint_path: SAM3æ¨¡å‹æƒé‡è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            device: è¿è¡Œè®¾å¤‡ï¼Œ"cuda"æˆ–"cpu"
        
        Raises:
            FileNotFoundError: å¦‚æœæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨
            RuntimeError: å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥
        """
        print("=" * 60)
        print("åˆå§‹åŒ– SAM3 åˆ†å‰²å™¨")
        print("=" * 60)
        
        # éªŒè¯è®¾å¤‡
        if device == "cuda" and not torch.cuda.is_available():
            print("âš ï¸  è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPUæ¨¡å¼")
            device = "cpu"
        
        self.device = device
        print(f"âœ“ è¿è¡Œè®¾å¤‡: {self.device}")
        
        # è®¾ç½®é»˜è®¤æ¨¡å‹è·¯å¾„
        if checkpoint_path is None:
            checkpoint_path = "/workspace/PartKep/models/SAM3/models--facebook--sam3/snapshots/3c879f39826c281e95690f02c7821c4de09afae7/sam3.pt"
            print(f"âœ“ ä½¿ç”¨é»˜è®¤æ¨¡å‹è·¯å¾„")
        
        self.checkpoint_path = checkpoint_path
        print(f"  è·¯å¾„: {self.checkpoint_path}")
        
        # éªŒè¯æ¨¡å‹æ–‡ä»¶å­˜åœ¨
        if not Path(checkpoint_path).exists():
            raise FileNotFoundError(
                f"SAM3æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}\n"
                f"è¯·ç¡®ä¿å·²ä¸‹è½½æ¨¡å‹åˆ°æ­£ç¡®ä½ç½®"
            )
        
        # åŠ è½½SAM3æ¨¡å‹
        print("\næ­£åœ¨åŠ è½½ SAM3 æ¨¡å‹...")
        try:
            self.model = build_sam3_image_model(checkpoint_path=checkpoint_path)
            self.processor = Sam3Processor(self.model)
            print("âœ… SAM3 æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            raise RuntimeError(f"SAM3æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        
        print("\n" + "=" * 60)
        print("âœ… SAM3 åˆ†å‰²å™¨åˆå§‹åŒ–å®Œæˆï¼")
        print("=" * 60)
        print()
    
    def segment_parts(self,
                     cropped_image: Union[np.ndarray, Image.Image],
                     label: str,
                     crop_bbox: List[int]) -> List[Dict]:
        """
        åˆ†å‰²ç‰©ä½“çš„æ‰€æœ‰éƒ¨ä»¶å¹¶æå–å…³é”®ç‚¹
        
        Args:
            cropped_image: è£å‰ªåçš„ç‰©ä½“å›¾åƒ
            label: ç‰©ä½“ç±»åˆ«ï¼ˆå¦‚"cup", "bottle"ï¼‰
            crop_bbox: è£å‰ªæ¡†åœ¨åŸå›¾çš„åƒç´ åæ ‡ [x1, y1, x2, y2]
        
        Returns:
            List[Dict]: æ¯ä¸ªéƒ¨ä»¶çš„åˆ†å‰²ç»“æœ
            [
                {
                    'part_name': 'handle',
                    'keypoint': (x, y),  # åŸå›¾åæ ‡ï¼ˆæµ®ç‚¹æ•°ï¼‰
                    'score': 0.95,       # SAM3ç½®ä¿¡åº¦
                    'mask': np.ndarray   # äºŒå€¼mask (H, W)
                },
                ...
            ]
        
        æ³¨æ„ï¼š
            - å¦‚æœæŸä¸ªéƒ¨ä»¶æœªæ£€æµ‹åˆ°ï¼Œä¼šè·³è¿‡å¹¶æ‰“å°è­¦å‘Š
            - å…³é”®ç‚¹åæ ‡æ˜¯æµ®ç‚¹æ•°ï¼Œä¿æŒäºšåƒç´ ç²¾åº¦
            - maskæ˜¯ç›¸å¯¹äºè£å‰ªå›¾çš„ï¼Œå…³é”®ç‚¹æ˜¯ç›¸å¯¹äºåŸå›¾çš„
        """
        print(f"\nğŸ” å¼€å§‹åˆ†å‰²ç‰©ä½“éƒ¨ä»¶: {label}")
        print(f"  è£å‰ªæ¡†ä½ç½®: {crop_bbox}")
        
        # 1. è½¬æ¢å›¾åƒæ ¼å¼
        if isinstance(cropped_image, np.ndarray):
            image_pil = Image.fromarray(cropped_image)
        elif isinstance(cropped_image, Image.Image):
            image_pil = cropped_image
        else:
            raise ValueError(
                f"ä¸æ”¯æŒçš„å›¾åƒç±»å‹: {type(cropped_image)}ï¼Œ"
                f"å¿…é¡»æ˜¯ numpy.ndarray æˆ– PIL.Image.Image"
            )
        
        # ç¡®ä¿æ˜¯RGBæ ¼å¼
        if image_pil.mode != 'RGB':
            image_pil = image_pil.convert('RGB')
        
        print(f"  è£å‰ªå›¾åƒå°ºå¯¸: {image_pil.size[0]}x{image_pil.size[1]}")
        
        # 2. ä»PartConfigè·å–éƒ¨ä»¶åˆ—è¡¨
        parts = PartConfig.get_parts(label)
        
        if len(parts) == 0:
            print(f"âš ï¸  è­¦å‘Š: ç‰©ä½“ '{label}' æ²¡æœ‰é¢„å®šä¹‰çš„éƒ¨ä»¶é…ç½®")
            return []
        
        print(f"  éƒ¨ä»¶åˆ—è¡¨: {parts}")
        
        # 3. è®¾ç½®å›¾åƒï¼ˆfeature reuseä¼˜åŒ–ï¼šåªè°ƒç”¨ä¸€æ¬¡ï¼‰
        print("\nğŸ“¸ è®¾ç½®å›¾åƒï¼ˆæå–backbone featuresï¼‰...")
        inference_state = self.processor.set_image(image_pil)
        print("âœ“ å›¾åƒç‰¹å¾æå–å®Œæˆ")
        
        # 4. å¾ªç¯å¤„ç†æ¯ä¸ªéƒ¨ä»¶
        results = []
        
        for idx, part_name in enumerate(parts):
            print(f"\n[{idx+1}/{len(parts)}] å¤„ç†éƒ¨ä»¶: {part_name}")
            
            try:
                # 4.1 ä½¿ç”¨SAM3åˆ†å‰²éƒ¨ä»¶
                print(f"  â†’ è°ƒç”¨SAM3åˆ†å‰²...")
                output = self.processor.set_text_prompt(
                    state=inference_state,
                    prompt=part_name
                )
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹ç»“æœ
                if len(output['masks']) == 0:
                    print(f"  âš ï¸  æœªæ£€æµ‹åˆ°éƒ¨ä»¶ '{part_name}'ï¼Œè·³è¿‡")
                    continue
                
                # å–ç¬¬ä¸€ä¸ªæ£€æµ‹ç»“æœï¼ˆç½®ä¿¡åº¦æœ€é«˜ï¼‰
                mask_tensor = output['masks'][0]  # shape=(1, H, W), bool
                score = float(output['scores'][0])
                
                print(f"  âœ“ æ£€æµ‹æˆåŠŸï¼Œç½®ä¿¡åº¦: {score:.3f}")
                
                # 4.2 è½¬æ¢maskä¸ºnumpyæ ¼å¼
                mask_np = mask_tensor.cpu().numpy().squeeze().astype(np.uint8) * 255
                print(f"  âœ“ Mask shape: {mask_np.shape}")
                
                # 4.3 æå–å…³é”®ç‚¹ï¼ˆç›¸å¯¹äºè£å‰ªå›¾ï¼‰
                print(f"  â†’ æå–å…³é”®ç‚¹...")
                keypoint_crop = self.extract_single_keypoint(mask_np)
                
                if keypoint_crop is None:
                    print(f"  âš ï¸  å…³é”®ç‚¹æå–å¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                print(f"  âœ“ å…³é”®ç‚¹ï¼ˆè£å‰ªå›¾åæ ‡ï¼‰: ({keypoint_crop[0]:.2f}, {keypoint_crop[1]:.2f})")
                
                # 4.4 è½¬æ¢åˆ°åŸå›¾åæ ‡
                keypoint_orig = self.transform_to_original_coords(
                    [keypoint_crop],
                    crop_bbox
                )[0]
                
                print(f"  âœ“ å…³é”®ç‚¹ï¼ˆåŸå›¾åæ ‡ï¼‰: ({keypoint_orig[0]:.2f}, {keypoint_orig[1]:.2f})")
                
                # 4.5 ä¿å­˜ç»“æœ
                results.append({
                    'part_name': part_name,
                    'keypoint': keypoint_orig,
                    'score': score,
                    'mask': mask_np
                })
                
                print(f"  âœ… éƒ¨ä»¶ '{part_name}' å¤„ç†å®Œæˆ")
                
            except Exception as e:
                print(f"  âŒ å¤„ç†éƒ¨ä»¶ '{part_name}' æ—¶å‡ºé”™: {e}")
                continue
        
        # 5. è¾“å‡ºæ€»ç»“
        print("\n" + "=" * 60)
        print(f"âœ… éƒ¨ä»¶åˆ†å‰²å®Œæˆï¼")
        print(f"  ç‰©ä½“: {label}")
        print(f"  æˆåŠŸåˆ†å‰²: {len(results)}/{len(parts)} ä¸ªéƒ¨ä»¶")
        for result in results:
            print(f"    - {result['part_name']}: "
                  f"keypoint=({result['keypoint'][0]:.1f}, {result['keypoint'][1]:.1f}), "
                  f"score={result['score']:.3f}")
        print("=" * 60)
        
        return results
    
    @staticmethod
    def extract_single_keypoint(mask_np: np.ndarray) -> Optional[Tuple[float, float]]:
        """
        ä»maskæå–å•ä¸ªå…³é”®ç‚¹ï¼ˆè´¨å¿ƒ+æœ€è¿‘ç‚¹æŠ•å½±æ–¹æ³•ï¼‰
        
        ç­–ç•¥ï¼š
            1. è®¡ç®—maskçš„è´¨å¿ƒ
            2. æ£€æŸ¥è´¨å¿ƒæ˜¯å¦åœ¨maskä¸Š
            3. å¦‚æœè´¨å¿ƒåœ¨maskä¸Šï¼Œç›´æ¥è¿”å›
            4. å¦‚æœè´¨å¿ƒåœ¨ç©ºæ´ä¸­ï¼ˆå¦‚handleï¼‰ï¼Œæ‰¾maskä¸Šè·ç¦»è´¨å¿ƒæœ€è¿‘çš„ç‚¹
        
        Args:
            mask_np: äºŒå€¼mask, shape=(H, W), dtype=uint8ï¼Œå€¼ä¸º0æˆ–255
        
        Returns:
            (x, y): å…³é”®ç‚¹åæ ‡ï¼ˆæµ®ç‚¹æ•°ï¼‰ï¼Œç›¸å¯¹äºmask
                   å¦‚æœæå–å¤±è´¥è¿”å›None
        
        Examples:
            >>> mask = np.zeros((100, 100), dtype=np.uint8)
            >>> mask[30:70, 30:70] = 255  # æ­£æ–¹å½¢
            >>> keypoint = SAM3Segmenter.extract_single_keypoint(mask)
            >>> print(keypoint)  # åº”è¯¥æ¥è¿‘ (50.0, 50.0)
        """
        # 1. æå–è½®å»“
        contours, _ = cv2.findContours(
            mask_np, 
            cv2.RETR_EXTERNAL, 
            cv2.CHAIN_APPROX_SIMPLE
        )
        
        if len(contours) == 0:
            return None
        
        # é€‰æ‹©æœ€å¤§çš„è½®å»“ï¼ˆé¢ç§¯æœ€å¤§ï¼‰
        contour = max(contours, key=cv2.contourArea)
        
        # 2. è®¡ç®—è´¨å¿ƒ
        M = cv2.moments(contour)
        
        if M["m00"] == 0:
            # é¢ç§¯ä¸º0ï¼Œæ— æ³•è®¡ç®—è´¨å¿ƒ
            return None
        
        cx = M["m10"] / M["m00"]  # è´¨å¿ƒxåæ ‡
        cy = M["m01"] / M["m00"]  # è´¨å¿ƒyåæ ‡
        
        # 3. æ£€æŸ¥è´¨å¿ƒæ˜¯å¦åœ¨maskä¸Š
        # éœ€è¦å…ˆæ£€æŸ¥åæ ‡æ˜¯å¦åœ¨å›¾åƒèŒƒå›´å†…
        cx_int = int(round(cx))
        cy_int = int(round(cy))
        
        if (0 <= cy_int < mask_np.shape[0] and 
            0 <= cx_int < mask_np.shape[1] and
            mask_np[cy_int, cx_int] > 0):
            # è´¨å¿ƒåœ¨maskä¸Šï¼Œç›´æ¥è¿”å›
            return (cx, cy)
        
        # 4. è´¨å¿ƒåœ¨ç©ºæ´ä¸­ï¼Œæ‰¾maskä¸Šè·ç¦»è´¨å¿ƒæœ€è¿‘çš„ç‚¹
        # è·å–æ‰€æœ‰maskä¸Šçš„ç‚¹
        mask_points = np.column_stack(np.where(mask_np > 0))  # shape=(N, 2), [row, col]
        
        if len(mask_points) == 0:
            return None
        
        # è®¡ç®—æ¯ä¸ªç‚¹åˆ°è´¨å¿ƒçš„è·ç¦»
        distances = np.sqrt(
            (mask_points[:, 1] - cx) ** 2 +  # mask_points[:, 1] æ˜¯ col (x)
            (mask_points[:, 0] - cy) ** 2     # mask_points[:, 0] æ˜¯ row (y)
        )
        
        # æ‰¾åˆ°æœ€è¿‘çš„ç‚¹
        closest_idx = np.argmin(distances)
        closest_point = mask_points[closest_idx]
        
        # è¿”å› (x, y) æ ¼å¼ï¼š(col, row)
        return (float(closest_point[1]), float(closest_point[0]))
    
    @staticmethod
    def transform_to_original_coords(
        keypoints: List[Tuple[float, float]], 
        crop_bbox: List[int]
    ) -> List[Tuple[float, float]]:
        """
        å°†è£å‰ªå›¾åæ ‡è½¬æ¢ä¸ºåŸå§‹å›¾åƒåæ ‡
        
        è½¬æ¢å…¬å¼ï¼š
            x_orig = x_crop + crop_bbox[0]  # crop_bbox[0] æ˜¯ x1
            y_orig = y_crop + crop_bbox[1]  # crop_bbox[1] æ˜¯ y1
        
        Args:
            keypoints: ç›¸å¯¹äºè£å‰ªå›¾çš„å…³é”®ç‚¹åˆ—è¡¨ [(x1, y1), (x2, y2), ...]
            crop_bbox: è£å‰ªæ¡†åœ¨åŸå›¾çš„åƒç´ åæ ‡ [x1, y1, x2, y2]
        
        Returns:
            List[Tuple[float, float]]: åŸå›¾åæ ‡ç³»çš„å…³é”®ç‚¹
        
        Examples:
            >>> crop_keypoints = [(10.5, 20.3), (30.0, 40.0)]
            >>> crop_bbox = [100, 200, 300, 400]
            >>> orig_keypoints = SAM3Segmenter.transform_to_original_coords(
            ...     crop_keypoints, crop_bbox
            ... )
            >>> print(orig_keypoints)
            [(110.5, 220.3), (130.0, 240.0)]
        """
        # æå–åç§»é‡
        x_offset = crop_bbox[0]  # x1
        y_offset = crop_bbox[1]  # y1
        
        # è½¬æ¢æ¯ä¸ªå…³é”®ç‚¹
        transformed_keypoints = [
            (x + x_offset, y + y_offset)
            for x, y in keypoints
        ]
        
        return transformed_keypoints
    
    def __repr__(self) -> str:
        """è¿”å›åˆ†å‰²å™¨çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (
            f"SAM3Segmenter(\n"
            f"  device={self.device},\n"
            f"  checkpoint={self.checkpoint_path}\n"
            f")"
        )


# ==================== æ¨¡å—æµ‹è¯•ä»£ç  ====================
if __name__ == "__main__":
    """
    æµ‹è¯•SAM3Segmenteråˆå§‹åŒ–
    è¿è¡Œæ–¹å¼: python sam3segmenter.py
    """
    try:
        print("å¼€å§‹æµ‹è¯• SAM3Segmenter åˆå§‹åŒ–...\n")
        
        # æµ‹è¯•åˆå§‹åŒ–
        segmenter = SAM3Segmenter(device="cuda")
        
        # æ‰“å°åˆ†å‰²å™¨ä¿¡æ¯
        print("\nåˆ†å‰²å™¨ä¿¡æ¯:")
        print(segmenter)
        
        print("\nâœ… åˆå§‹åŒ–æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()