"""
Created by Yinghao Ho on 2026-1-19
Modified for Hugging Face integration on 2026-1-30
"""

from pathlib import Path
from typing import List, Dict, Optional, Union
import numpy as np
import torch
from PIL import Image
from torchvision.ops import nms

# å¯¼å…¥é…ç½®
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))
from configs.groundingdino_cfg import GroundingDINOConfig


class GroundingDINODetector:
    """
    Grounding DINOç‰©ä½“æ£€æµ‹å™¨ (Hugging Faceç‰ˆæœ¬)
    
    ä¸»è¦å˜åŒ–ï¼š
        - ä½¿ç”¨ transformers åº“çš„å®˜æ–¹å®ç°
        - è‡ªåŠ¨å¤„ç†æ¨¡å‹ä¸‹è½½å’Œç¼“å­˜
        - ç®€åŒ–é¢„å¤„ç†æµç¨‹
        - ä¿æŒå®Œå…¨ç›¸åŒçš„æ¥å£å’Œè¿”å›æ ¼å¼
    
    åŠŸèƒ½ï¼š
        - åŸºäºæ–‡æœ¬promptæ£€æµ‹å›¾åƒä¸­çš„ç‰©ä½“
        - æ”¯æŒå¼€æ”¾è¯æ±‡æ£€æµ‹ï¼ˆä¸é™äºé¢„å®šä¹‰ç±»åˆ«ï¼‰
        - æ”¯æŒç©ºé—´å…³ç³»æ¨ç†ï¼ˆå¦‚"the leftmost cup"ï¼‰
        - æ¯ä¸ªç±»åˆ«åªè¿”å›ç½®ä¿¡åº¦æœ€é«˜çš„ä¸€ä¸ªæ£€æµ‹ç»“æœ
    
    è¾“å…¥ï¼š
        - RGBå›¾åƒ (H, W, 3) - PIL.Image æˆ– numpy array
        - æ–‡æœ¬promptï¼ˆå¦‚"cup", "cup . bottle"ï¼‰
    
    è¾“å‡ºï¼š
        - æ£€æµ‹ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«bboxï¼ˆå½’ä¸€åŒ–åæ ‡ï¼‰ã€labelã€score
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        >>> detector = GroundingDINODetector()
        >>> results = detector.detect(image, "the leftmost cup")
        >>> print(results)
        [{'bbox': [0.1, 0.2, 0.5, 0.8], 'label': 'cup', 'score': 0.95}]
    
    åç»­å·¥ä½œæµç¨‹ï¼š
        1. GroundingDINOæ£€æµ‹ â†’ è¿”å›å½’ä¸€åŒ–bbox
        2. ImageProcessorè£å‰ª â†’ ä¿å­˜ROIå›¾åƒï¼Œè®°å½•offset
        3. SAM3å¤„ç†ROI â†’ æå–å…³é”®ç‚¹ï¼ˆROIåæ ‡ç³»ï¼‰
        4. CoordinateTransformer â†’ è½¬æ¢å›åŸå›¾åæ ‡ç³»
    """
    
    def __init__(self,
                 device: str = "cuda",
                 model_id: Optional[str] = None):
        """
        åˆå§‹åŒ–Grounding DINOæ£€æµ‹å™¨ï¼ˆHugging Faceç‰ˆæœ¬ï¼‰
        
        Args:
            device (str): è¿è¡Œè®¾å¤‡ï¼Œå¯é€‰"cuda"æˆ–"cpu"ï¼Œé»˜è®¤ä¸º"cuda"
            model_id (str, optional): Hugging Faceæ¨¡å‹IDã€‚
                å¦‚æœä¸ºNoneï¼Œåˆ™ä»GroundingDINOConfigè¯»å–é»˜è®¤MODEL_IDã€‚
                å¯é€‰å€¼ï¼š
                    - "IDEA-Research/grounding-dino-base" (æ¨èï¼Œå¯¹åº”SwinB)
                    - "IDEA-Research/grounding-dino-tiny" (æ›´å¿«ä½†ç²¾åº¦ç¨ä½)
        
        Raises:
            ImportError: å¦‚æœtransformersåº“æœªå®‰è£…æˆ–ç‰ˆæœ¬ä¸å…¼å®¹
            ValueError: å¦‚æœdeviceå‚æ•°æ— æ•ˆ
            RuntimeError: å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥
        
        æ³¨æ„ï¼š
            - é¦–æ¬¡åˆå§‹åŒ–ä¼šè‡ªåŠ¨ä¸‹è½½çº¦1.5GBçš„æ¨¡å‹æƒé‡
            - æ¨¡å‹ä¼šç¼“å­˜åˆ° ~/.cache/huggingface (æˆ–è‡ªå®šä¹‰CACHE_DIR)
            - å¦‚æœä½¿ç”¨GPUï¼Œéœ€è¦ç¡®ä¿CUDAå¯ç”¨
        """
        print("=" * 60)
        print("åˆå§‹åŒ– Grounding DINO æ£€æµ‹å™¨ (Hugging Faceç‰ˆæœ¬)")
        print("=" * 60)
        
        # ==================== 1. å‚æ•°éªŒè¯ ====================
        if device not in ["cuda", "cpu"]:
            raise ValueError(f"æ— æ•ˆçš„è®¾å¤‡ç±»å‹: {device}ï¼Œå¿…é¡»æ˜¯ 'cuda' æˆ– 'cpu'")
        
        # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
        if device == "cuda" and not torch.cuda.is_available():
            print("âš ï¸  è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPUæ¨¡å¼")
            device = "cpu"
        
        self.device = device
        print(f"âœ“ è¿è¡Œè®¾å¤‡: {self.device}")
        
        # ==================== 2. ç¡®å®šæ¨¡å‹è·¯å¾„ ====================
        # å¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šmodel_idï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶çš„é»˜è®¤å€¼
        if model_id is None:
            model_path = GroundingDINOConfig.get_model_path()
            print(f"âœ“ ä½¿ç”¨é»˜è®¤æ¨¡å‹: {model_path}")
        else:
            model_path = model_id
            print(f"âœ“ ä½¿ç”¨æŒ‡å®šæ¨¡å‹: {model_path}")
        
        self.model_id = model_path
        
        # è·å–ç¼“å­˜ç›®å½•é…ç½®
        cache_dir = GroundingDINOConfig.CACHE_DIR
        if cache_dir:
            print(f"âœ“ ç¼“å­˜ç›®å½•: {cache_dir}")
        else:
            print(f"âœ“ ç¼“å­˜ç›®å½•: ~/.cache/huggingface (é»˜è®¤)")
        
        # ==================== 3. åŠ è½½æ£€æµ‹å‚æ•° ====================
        self.box_threshold = GroundingDINOConfig.BOX_THRESHOLD
        self.text_threshold = GroundingDINOConfig.TEXT_THRESHOLD
        self.nms_threshold = GroundingDINOConfig.NMS_THRESHOLD
        
        print(f"\nâœ“ æ£€æµ‹å‚æ•°:")
        print(f"  - BOX_THRESHOLD: {self.box_threshold}")
        print(f"  - TEXT_THRESHOLD: {self.text_threshold}")
        print(f"  - NMS_THRESHOLD: {self.nms_threshold}")
        
        # ==================== 4. å¯¼å…¥ Hugging Face åº“ ====================
        print("\næ­£åœ¨å¯¼å…¥ transformers åº“...")
        try:
            from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection
            print("âœ“ transformers å¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            raise ImportError(
                "âŒ æ— æ³•å¯¼å…¥ transformers åº“\n"
                "ğŸ“¥ è¯·å®‰è£…: pip install transformers>=4.35.0\n"
                f"é”™è¯¯è¯¦æƒ…: {e}"
            )
        
        # ==================== 5. åŠ è½½ Processor ====================
        print("\næ­£åœ¨åŠ è½½ Processor...")
        print("ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰")
        
        try:
            self.processor = AutoProcessor.from_pretrained(
                model_path,
                cache_dir=cache_dir
            )
            print("âœ“ Processor åŠ è½½æˆåŠŸ")
        except Exception as e:
            raise RuntimeError(
                f"âŒ Processor åŠ è½½å¤±è´¥\n"
                f"å¯èƒ½åŸå› ï¼š\n"
                f"  1. ç½‘ç»œè¿æ¥é—®é¢˜ï¼ˆæ— æ³•è®¿é—® Hugging Faceï¼‰\n"
                f"  2. æ¨¡å‹IDä¸æ­£ç¡®: {model_path}\n"
                f"  3. ç£ç›˜ç©ºé—´ä¸è¶³\n"
                f"é”™è¯¯è¯¦æƒ…: {e}"
            )
        
        # ==================== 6. åŠ è½½ Model ====================
        print("\næ­£åœ¨åŠ è½½æ¨¡å‹...")
        print("ï¼ˆè¿™å¯èƒ½éœ€è¦10-30ç§’ï¼Œè¯·ç¨å€™ï¼‰")
        
        try:
            self.model = AutoModelForZeroShotObjectDetection.from_pretrained(
                model_path,
                cache_dir=cache_dir
            )
            
            # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            self.model = self.model.to(self.device)
            
            print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"  è®¾å¤‡: {self.device}")
            
        except Exception as e:
            raise RuntimeError(
                f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥\n"
                f"é”™è¯¯è¯¦æƒ…: {e}"
            )
        
        # ==================== 7. è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ ====================
        self.model.eval()
        
        print("\n" + "=" * 60)
        print("âœ… Grounding DINO æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆï¼")
        print("=" * 60)
        print()
    
    def detect(self,
               image: Union[np.ndarray, Image.Image],
               text_prompt: str,
               box_threshold: Optional[float] = None,
               text_threshold: Optional[float] = None) -> List[Dict]:
        """
        æ£€æµ‹å›¾åƒä¸­çš„ç‰©ä½“
        
        Args:
            image: RGBå›¾åƒï¼Œshape=(H, W, 3)ï¼Œdtype=uint8
                   æˆ–è€…PIL.Imageå¯¹è±¡
            text_prompt: æ–‡æœ¬æç¤ºï¼Œå¦‚ "cup" æˆ– "cup . bottle"
                        æ³¨æ„ï¼šå¤šä¸ªç‰©ä½“ç”¨ç©ºæ ¼å’Œç‚¹å·åˆ†éš”ï¼Œå¦‚ "cup . bottle"
            box_threshold: è¾¹ç•Œæ¡†é˜ˆå€¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼ï¼‰
            text_threshold: æ–‡æœ¬é˜ˆå€¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼ï¼‰
        
        Returns:
            List[Dict]: æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªç±»åˆ«åªä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„ä¸€ä¸ª
            [
                {
                    'bbox': [x1, y1, x2, y2],  # å½’ä¸€åŒ–åæ ‡ [0, 1]
                    'label': 'cup',
                    'score': 0.95
                },
                ...
            ]
            
        Raises:
            ValueError: å¦‚æœå›¾åƒæ ¼å¼ä¸æ­£ç¡®
            RuntimeError: å¦‚æœæ£€æµ‹è¿‡ç¨‹å‡ºé”™
        
        æ³¨æ„ï¼š
            - è¿”å›çš„bboxæ˜¯å½’ä¸€åŒ–åæ ‡ [0, 1]ï¼Œä¸‹æ¸¸éœ€è¦ä¹˜ä»¥å›¾åƒå°ºå¯¸
            - ImageProcessorä¼šä½¿ç”¨è¿™äº›å½’ä¸€åŒ–åæ ‡è¿›è¡Œè£å‰ª
            - SAM3å¤„ç†è£å‰ªåçš„ROIï¼Œéœ€è¦ç”¨CoordinateTransformerè½¬å›åŸå›¾åæ ‡
        """
        # ==================== ç¬¬1æ­¥ï¼šè¾“å…¥éªŒè¯ ====================
        
        # 1.1 éªŒè¯text_prompt
        if not text_prompt or not isinstance(text_prompt, str):
            raise ValueError("text_promptå¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
        
        # 1.2 è®¾ç½®é˜ˆå€¼ï¼ˆå¦‚æœæœªæŒ‡å®šï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶çš„é»˜è®¤å€¼ï¼‰
        if box_threshold is None:
            box_threshold = self.box_threshold
        if text_threshold is None:
            text_threshold = self.text_threshold
        
        # éªŒè¯é˜ˆå€¼èŒƒå›´
        if not 0.0 <= box_threshold <= 1.0:
            raise ValueError(f"box_thresholdå¿…é¡»åœ¨[0, 1]èŒƒå›´å†…ï¼Œå½“å‰å€¼ï¼š{box_threshold}")
        if not 0.0 <= text_threshold <= 1.0:
            raise ValueError(f"text_thresholdå¿…é¡»åœ¨[0, 1]èŒƒå›´å†…ï¼Œå½“å‰å€¼ï¼š{text_threshold}")
        
        # 1.3 éªŒè¯å›¾åƒæ ¼å¼å¹¶è½¬æ¢ä¸ºPIL Image
        if isinstance(image, np.ndarray):
            # numpy arrayè¾“å…¥ï¼ˆæ¥è‡ªOpenCVæˆ–ç›¸æœºï¼‰
            
            # æ£€æŸ¥ç»´åº¦
            if image.ndim != 3:
                raise ValueError(
                    f"å›¾åƒå¿…é¡»æ˜¯3ç»´æ•°ç»„ (H, W, 3)ï¼Œå½“å‰ç»´åº¦ï¼š{image.ndim}"
                )
            
            # æ£€æŸ¥é€šé“æ•°
            if image.shape[2] != 3:
                raise ValueError(
                    f"å›¾åƒå¿…é¡»æ˜¯3é€šé“RGBæ ¼å¼ï¼Œå½“å‰é€šé“æ•°ï¼š{image.shape[2]}"
                )
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            if image.dtype != np.uint8:
                # å°è¯•è½¬æ¢
                if image.dtype in [np.float32, np.float64]:
                    # å¦‚æœæ˜¯æµ®ç‚¹æ•°ä¸”åœ¨[0,1]èŒƒå›´ï¼Œè½¬æ¢ä¸º[0,255]
                    if image.max() <= 1.0:
                        image = (image * 255).astype(np.uint8)
                    else:
                        image = image.astype(np.uint8)
                else:
                    image = image.astype(np.uint8)
            
            # è½¬æ¢ä¸ºPIL Imageï¼ˆå‡è®¾å·²ç»æ˜¯RGBæ ¼å¼ï¼‰
            image_pil = Image.fromarray(image)
            
        elif isinstance(image, Image.Image):
            # å·²ç»æ˜¯PIL Image
            image_pil = image
            
            # ç¡®ä¿æ˜¯RGBæ¨¡å¼
            if image_pil.mode != 'RGB':
                image_pil = image_pil.convert('RGB')
        
        else:
            raise ValueError(
                f"imageå¿…é¡»æ˜¯numpy.ndarrayæˆ–PIL.Image.Imageç±»å‹ï¼Œ"
                f"å½“å‰ç±»å‹ï¼š{type(image)}"
            )
        
        # ä¿å­˜åŸå§‹å›¾åƒå°ºå¯¸
        image_width, image_height = image_pil.size
        
        # ==================== å…³é”®ï¼šæ ¼å¼åŒ– text_prompt ====================
        # å®˜æ–¹æ–‡æ¡£å¼ºè°ƒï¼štext queries need to be lowercased + end with a dot
        # https://huggingface.co/IDEA-Research/grounding-dino-base
        text_prompt_formatted = text_prompt.lower()
        if not text_prompt_formatted.endswith('.'):
            text_prompt_formatted = text_prompt_formatted + '.'
        
        print(f"ğŸ“· è¾“å…¥å›¾åƒå°ºå¯¸: {image_width} x {image_height}")
        print(f"ğŸ¯ æ–‡æœ¬æç¤º: '{text_prompt}' â†’ '{text_prompt_formatted}'")
        print(f"âš™ï¸  æ£€æµ‹é˜ˆå€¼: box={box_threshold:.2f}, text={text_threshold:.2f}")
        
        # ==================== ç¬¬2æ­¥ï¼šHugging Face é¢„å¤„ç† ====================
        print("ğŸ”„ æ­£åœ¨é¢„å¤„ç†å›¾åƒ...")
        
        try:
            # ä½¿ç”¨æ ¼å¼åŒ–åçš„ text_promptï¼ˆå°å†™+å¥å·ï¼‰
            inputs = self.processor(
                images=image_pil,
                text=text_prompt_formatted,  # ä½¿ç”¨æ ¼å¼åŒ–åçš„ prompt
                return_tensors="pt"
            ).to(self.device)  # å®˜æ–¹æ¨èï¼šç›´æ¥ .to(device)
            
            print(f"âœ“ å›¾åƒé¢„å¤„ç†å®Œæˆ")
            
        except Exception as e:
            raise RuntimeError(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
        
        # ==================== ç¬¬3æ­¥ï¼šæ¨¡å‹æ¨ç† ====================
        print("ğŸš€ æ­£åœ¨è¿è¡Œæ¨¡å‹æ¨ç†...")
        
        try:
            with torch.no_grad():
                outputs = self.model(**inputs)
            
            print(f"âœ“ æ¨¡å‹æ¨ç†å®Œæˆ")
            
        except Exception as e:
            raise RuntimeError(f"æ¨¡å‹æ¨ç†å¤±è´¥: {e}")
        
        # ==================== ç¬¬4æ­¥ï¼šHugging Face åå¤„ç† ====================
        print("ğŸ”§ æ­£åœ¨åå¤„ç†æ£€æµ‹ç»“æœ...")
        
        try:
            # ä½¿ç”¨å®˜æ–¹å‚æ•°åï¼šbox_thresholdï¼ˆä¸æ˜¯ thresholdï¼‰
            # inputs ç°åœ¨æ˜¯ BatchFeature å¯¹è±¡ï¼Œæ”¯æŒ .input_ids å±æ€§è®¿é—®
            results_hf = self.processor.post_process_grounded_object_detection(
                outputs,
                inputs.input_ids,               # BatchFeature å¯¹è±¡æ”¯æŒå±æ€§è®¿é—®
                threshold=box_threshold,    # å®˜æ–¹å‚æ•°å
                text_threshold=text_threshold,  # å®˜æ–¹å‚æ•°å
                target_sizes=[(image_height, image_width)]  # (height, width)
            )[0]
            
            print(f"âœ“ HFåå¤„ç†å®Œæˆ")
            
        except Exception as e:
            raise RuntimeError(f"åå¤„ç†å¤±è´¥: {e}")
        
        # ==================== ç¬¬5æ­¥ï¼šæå–æ•°æ® ====================
        # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹ç»“æœ
        if len(results_hf['boxes']) == 0:
            print("âš ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“")
            return []
        
        # æå–æ•°æ®
        boxes_abs = results_hf['boxes'].cpu().numpy()    # (N, 4) [x1,y1,x2,y2] ç»å¯¹åƒç´ åæ ‡
        scores_np = results_hf['scores'].cpu().numpy()   # (N,)
        labels_list = results_hf['labels']               # List[str]
        
        print(f"  æ£€æµ‹åˆ° {len(boxes_abs)} ä¸ªå€™é€‰æ¡†")
        
        # ==================== ç¬¬6æ­¥ï¼šåæ ‡å½’ä¸€åŒ–ï¼ˆå…³é”®ï¼ï¼‰====================
        # HFè¿”å›çš„æ˜¯ç»å¯¹åƒç´ åæ ‡ï¼Œéœ€è¦å½’ä¸€åŒ–åˆ° [0, 1]
        # è¿™æ ·ImageProcessorå’Œä¸‹æ¸¸ä»£ç æ‰èƒ½æ­£ç¡®ä½¿ç”¨
        boxes_norm = boxes_abs / np.array([image_width, image_height, 
                                          image_width, image_height])
        
        # ç¡®ä¿åæ ‡åœ¨[0, 1]èŒƒå›´å†…
        boxes_norm = np.clip(boxes_norm, 0.0, 1.0)
        
        print(f"âœ“ åæ ‡å½’ä¸€åŒ–å®Œæˆ")
        
        # ==================== ç¬¬7æ­¥ï¼šNMS å»é‡ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰====================
        # æ³¨æ„ï¼šHFçš„post_processå·²ç»åšäº†ä¸€äº›è¿‡æ»¤ï¼Œä½†æˆ‘ä»¬ä¿ç•™åŸæœ‰çš„NMSé€»è¾‘
        # ä»¥ç¡®ä¿è¡Œä¸ºå®Œå…¨ä¸€è‡´
        
        boxes_tensor = torch.from_numpy(boxes_abs).float()
        scores_tensor = torch.from_numpy(scores_np).float()
        keep_indices = nms(boxes_tensor, scores_tensor, self.nms_threshold)
        keep_indices = keep_indices.numpy()
        
        # è¿‡æ»¤ç»“æœ
        boxes_norm = boxes_norm[keep_indices]
        scores_np = scores_np[keep_indices]
        labels_list = [labels_list[i] for i in keep_indices]
        
        print(f"  NMSåä¿ç•™: {len(boxes_norm)} ä¸ªæ¡†")
        
        # ==================== ç¬¬8æ­¥ï¼šæ¯ç±»å»é‡ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰====================
        # æ¯ä¸ªç±»åˆ«åªä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„ä¸€ä¸ªç»“æœ
        results_dict = {}
        
        for i in range(len(labels_list)):
            label = labels_list[i]
            score = float(scores_np[i])
            bbox = boxes_norm[i].tolist()  # [x1, y1, x2, y2] å½’ä¸€åŒ–åæ ‡
            
            # å¦‚æœè¿™ä¸ªç±»åˆ«è¿˜æ²¡æœ‰è®°å½•ï¼Œæˆ–è€…å½“å‰åˆ†æ•°æ›´é«˜ï¼Œåˆ™æ›´æ–°
            if label not in results_dict or score > results_dict[label]['score']:
                results_dict[label] = {
                    'bbox': bbox,
                    'label': label,
                    'score': score
                }
        
        # ==================== ç¬¬9æ­¥ï¼šè¿”å›ç»“æœ ====================
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰scoreé™åºæ’åˆ—
        results = list(results_dict.values())
        results.sort(key=lambda x: x['score'], reverse=True)
        
        print(f"âœ“ åå¤„ç†å®Œæˆ")
        print(f"  æœ€ç»ˆç»“æœæ•°: {len(results)}")
        for result in results:
            print(f"    - {result['label']}: score={result['score']:.3f}, "
                  f"bbox=[{result['bbox'][0]:.3f}, {result['bbox'][1]:.3f}, "
                  f"{result['bbox'][2]:.3f}, {result['bbox'][3]:.3f}]")
        
        return results
    
    def __repr__(self) -> str:
        """è¿”å›æ£€æµ‹å™¨çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (
            f"GroundingDINODetector(\n"
            f"  model_id={self.model_id},\n"
            f"  device={self.device},\n"
            f"  box_threshold={self.box_threshold},\n"
            f"  text_threshold={self.text_threshold},\n"
            f"  nms_threshold={self.nms_threshold}\n"
            f")"
        )


# ==================== æ¨¡å—æµ‹è¯•ä»£ç  ====================
if __name__ == "__main__":
    """
    æµ‹è¯•æ£€æµ‹å™¨åˆå§‹åŒ–
    è¿è¡Œæ–¹å¼: python modules/groundingdino.py
    """
    try:
        print("å¼€å§‹æµ‹è¯• GroundingDINODetector (Hugging Faceç‰ˆæœ¬)...\n")
        
        # æµ‹è¯•åˆå§‹åŒ–
        detector = GroundingDINODetector(device="cuda")
        
        # æ‰“å°æ£€æµ‹å™¨ä¿¡æ¯
        print("\næ£€æµ‹å™¨ä¿¡æ¯:")
        print(detector)
        
        print("\nâœ… åˆå§‹åŒ–æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ’¡ æç¤ºï¼š")
        print("   - æ¨¡å‹å·²ç¼“å­˜ï¼Œä¸‹æ¬¡å¯åŠ¨ä¼šæ›´å¿«")
        print("   - å¦‚éœ€æµ‹è¯•æ£€æµ‹åŠŸèƒ½ï¼Œè¯·è¿è¡Œ detector.py")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()